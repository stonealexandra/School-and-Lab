---
title: "Assignment 4"
author: "Alexandra Stone"
date: "October 9, 2018"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
#Problem 1 Build an R Notebook of the SMS message filtering example in the textbook on pages 103 to 123. Show each step and add appropriate documentation. This is the same as Lesson 4

###read in sms file and set columns as type and text
```{r}
library(readr)
sms_raw <- read_delim("C:/Users/user/Desktop/Skeet/Spring 2018/Stats/Module05/smsspamcollection/SMSSpamCollection.txt", 
"\t", escape_double = FALSE, col_names = c("type", "text"))
str(sms_raw)
```

###Since type is a categorical value, convert it into a factor and examine the data
```{r}
sms_raw$type<-factor(sms_raw$type)
str(sms_raw$type)
table(sms_raw$type)
```
###Install tm package
```{r}
library(tm)
```
###First step to processing text data involves creating a collection of text documents known as a corpus.  tm package has the VCorpus() function.  VCorpus() is volatile.  It requires us to specify the source of the documents we will use.  We can use VectorSource() since we already loaded the text into R
```{r}
sms_corpus<-VCorpus(VectorSource(sms_raw$text))
print(sms_corpus)
```
###Inspect and view actual message texts. lapply to view multiple
```{r}
inspect(sms_corpus[1:2])
as.character(sms_corpus[[1]])
lapply(sms_corpus[1:2], as.character)
```
###In order to standardize the words we must clean the text by removing punctuation or other characters that could clutter the result.  tm_map() function applies transformation/mapping to a tm corpus.  The result will be saved in a new object called corpus_clean.  Only use lowercase characters to standardize can be achieved using tolower and content_transformer and check result
```{r}
sms_corpus_clean<-tm_map(sms_corpus, content_transformer(tolower))
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
```
###remove numbers, stop words, punctuation
```{r}
sms_corpus_clean<-tm_map(sms_corpus_clean,removeNumbers)
sms_corpus_clean<-tm_map(sms_corpus_clean, removeWords, stopwords())
sms_corpus_clean<-tm_map(sms_corpus_clean, removePunctuation)
```
###create a replacePunctuation function 
```{r}
replacePunctuation<-function(x){gsub("[[:punct:]]+", " ", x)}
```

###Stemming is another standardization for text data that reduces words to their root form. SnowballC has a wordStem() function which returns the same vector of terms in the root form for the character vector and stemDocument allows wordStem() to be applied to the whole document. 
```{r}
library(SnowballC)
wordStem(c("learn", "learned", "learning", "learns"))
sms_corpus_clean<-tm_map(sms_corpus_clean, stemDocument)
```
###strip whitespace and check work
```{r}
sms_corpus_clean<-tm_map(sms_corpus_clean,stripWhitespace)
as.character(sms_corpus[[1]])
as.character(sms_corpus_clean[[1]])
```
###split the messages into individual components through tokenization.  The DocumentTermMatrix() function will take a corpus and create a data structure called a DTM in which rows indicated sms messages and columns indicate words/terms
```{r}
sms_dtm<-DocumentTermMatrix(sms_corpus_clean)

#unprocessed SMS corpus
sms_dtm2<-DocumentTermMatrix(sms_corpus, control = list(tolower =  TRUE, removeNumbers= TRUE, stopwords = TRUE, removePunctuation = TRUE, stemming = TRUE ))

#unprocessed SMS corpus
sms_dtm2<-DocumentTermMatrix(sms_corpus, control = list(tolower =  TRUE, removeNumbers= TRUE, stopwords = function(x) {removeWords(x,stopwords())}, removePunctuation = TRUE, stemming = TRUE ))
sms_dtm
sms_dtm2

```
###Data Preparation: split data into training and test sets

```{r}
sms_dtm_train<-sms_dtm[1:4179,]
sms_dtm_test<-sms_dtm[4180:5572,]
sms_train_labels<-sms_raw[1:4179,]$type
sms_test_labels<-sms_raw[4180:5572,]$type
prop.table(table(sms_train_labels))
prop.table(table(sms_test_labels))
```
###Wordcloud can help visualize clouds for spam and ham to help us gauge whether our Naive Bayes spam filter will work
```{r}
library(wordcloud)
wordcloud(sms_corpus_clean, min.freq = 50, random.order = FALSE)
spam<-subset(sms_raw, type == "spam")
ham<-subset(sms_raw, type == "ham")
wordcloud(spam$text, max.words = 40, scale = c(3, 0.5))
wordcloud(ham$text, max.words = 40, scale = c(3, 0.5))
```
###Data preparation: Creating indicator features for frequent words
####Final step in the data preparation process is to turn the matrix into a structure that is capable of training a Naive Bayes classifier.  Eliminate words that appear in less than five SMS messages.  The findFreqTerms() function takes a DTM and returns a character vector of words that appear for the minimum specified times.  
```{r}
sms_freq_words<-findFreqTerms(sms_dtm_train, 5)
str(sms_freq_words)
sms_dtm_freq_train<-sms_dtm_train[,sms_freq_words]
sms_dtm_freq_test<-sms_dtm_test[,sms_freq_words]
```
###The Naive Bayes classifier is typically trained on data with categorical features which poses a problem since the cells in the matrix are numeric.  convert_counts() function converts counts to Yes/No strings.  The apply () function allows a function to be used on each of the rows or columns in a matrix.
```{r}
convert_counts<-function(x){ x<-ifelse(x > 0, "Yes", "No")}
sms_train<-apply(sms_dtm_freq_train, MARGIN = 2, convert_counts)
sms_test<-apply(sms_dtm_freq_test, MARGIN = 2, convert_counts)
```
###Training a model on the data
####The Naive Bayes algorithm will use the presence or absence of words to estimate the probability that a given SMS message is spam

```{r}
library(e1071)
sms_classifier<- naiveBayes(sms_train, sms_train_labels)
```
###Evaluate Model performance
```{r}
sms_test_pred<-predict(sms_classifier, sms_test)
```
###Compare predictions
```{r}
library(gmodels)
CrossTable(sms_test_pred, sms_test_labels,prop.chisq = FALSE, prop.t = FALSE, dnn = c('predicted', 'actual'))
```
###Improving model performance
####reduced number of false positives using laplace
```{r}
sms_classifier2<-naiveBayes(sms_train, sms_train_labels, laplace = 1)
sms_test_pred2<-predict(sms_classifier2, sms_test)
CrossTable(sms_test_pred2, sms_test_labels, prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE, dnn = c('predicted', 'actual'))
```
#Problem 2 Install the requisite packages to execute the following code that classifies the built-in iris data using Naive Bayes. Build an R Notebook and explain in detail what each step does. Be sure to look up each function to understand how it is used.
```{r}
#later, promises packages had to be installed also
library(later)
library(promises)
library(klaR)
data(iris)

#explore dataset
#nrow(iris)
#summary(iris)
head(iris)

# identify indexes to be in testing dataset
# every index of 5th, 10th, 15th .. will be the testing dataset
# the rest are training dataset
testidx <- which(1:length(iris[, 1]) %% 5 == 0)

# separate into training and testing datasets
# training set has 120 obs and test has 30 obs
iristrain <- iris[-testidx,]
iristest <- iris[testidx,]

# apply Naive Bayes. Compute conditional a-posterior probabilities of a categorical class variable given independent predictor variables using the Bayes rule.
nbmodel <- NaiveBayes(Species~., data=iristrain)

# check the accuracy
# predict function used to make predicions
# store predictions in prediction
# compare predictions to true values using table()
prediction <- predict(nbmodel, iristest[,-5])
table(prediction$class, iristest[,5])
```
###To make prediction for a new case using this model, you would set the new cases as the test case

###In order to deal with numeric features you would have to convert them to factors.  convert_counts() function converts counds to Yes/No strings.  The apply () function allows a function to be used on each of the rows or columns in a matrix.

###Laplace estimator is specified as fL in NaiveBayes(x, grouping, prior, usekernel = FALSE, fL = 0, ...).  If no fL is specified, the default is no correction. 

#Problem 3: What are Laplace estimators and why are they used in Naive Bayes classification? Provide an example of how they might be used and when. (You do not need to write any code. Instead explain their use in the R Notebook.)

##Laplace estimators add a small number to each of the counts in the frequency table to ensure that each feature's probability is nonzero.  It is usefulwith the Naive Bayes formula because the Naive Bayes formula multiplies probabilities in a chain. Therefore, if an event never occured it would be set at zero percent, and the posterior probability would also be zero.  
